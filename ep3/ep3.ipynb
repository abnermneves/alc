{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before you turn this problem in, make sure everything runs as expected. First, **restart the kernel** (in the menubar, select Kernel$\\rightarrow$Restart) and then **run all cells** (in the menubar, select Cell$\\rightarrow$Run All).\n",
    "\n",
    "Make sure you fill in any place that says `YOUR CODE HERE` or \"YOUR ANSWER HERE\", as well as your name and collaborators below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "NAME = \"\"\n",
    "COLLABORATORS = \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "30fe04fad4f881ddacc44b34f71c815f",
     "grade": false,
     "grade_id": "cell-5802f858353a14fb",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "# Exercício Prático 3: PCA\n",
    "\n",
    "Neste exercício vamos estudar as representações de baixa dimensão obtidas pelo PCA. O objetivo é reproduzir os resultados obtidos usando o módulo sklearn.decomposition.PCA usando apenas o numpy. Para isto, vamos utilizar os dados contidos em ```p1.txt```.\n",
    "\n",
    "O conjunto de dados ```p1.txt``` contém recordes nacionais femininos em corridas de 100m, 200m e 400m rasos em segundos e corridas de longa distância em minutos. Os nomes das variáveis não estão incluídos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "8e4cb4cec05cc42123f733a3011b169b",
     "grade": false,
     "grade_id": "cell-4190b58ea79cb263",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Country</th>\n",
       "      <th>100m</th>\n",
       "      <th>200m</th>\n",
       "      <th>400m</th>\n",
       "      <th>800m</th>\n",
       "      <th>1500m</th>\n",
       "      <th>3000m</th>\n",
       "      <th>Marathon</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ARG</td>\n",
       "      <td>10.83</td>\n",
       "      <td>22.67</td>\n",
       "      <td>50.56</td>\n",
       "      <td>2.00</td>\n",
       "      <td>4.09</td>\n",
       "      <td>8.96</td>\n",
       "      <td>153.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AUS</td>\n",
       "      <td>11.12</td>\n",
       "      <td>22.23</td>\n",
       "      <td>48.63</td>\n",
       "      <td>1.98</td>\n",
       "      <td>4.02</td>\n",
       "      <td>8.63</td>\n",
       "      <td>143.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AUT</td>\n",
       "      <td>11.15</td>\n",
       "      <td>22.70</td>\n",
       "      <td>50.62</td>\n",
       "      <td>1.94</td>\n",
       "      <td>4.05</td>\n",
       "      <td>8.78</td>\n",
       "      <td>154.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BEL</td>\n",
       "      <td>11.14</td>\n",
       "      <td>22.48</td>\n",
       "      <td>51.45</td>\n",
       "      <td>1.97</td>\n",
       "      <td>4.08</td>\n",
       "      <td>8.82</td>\n",
       "      <td>143.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BER</td>\n",
       "      <td>11.46</td>\n",
       "      <td>23.05</td>\n",
       "      <td>53.30</td>\n",
       "      <td>2.07</td>\n",
       "      <td>4.29</td>\n",
       "      <td>9.81</td>\n",
       "      <td>174.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>BRA</td>\n",
       "      <td>11.17</td>\n",
       "      <td>22.60</td>\n",
       "      <td>50.62</td>\n",
       "      <td>1.97</td>\n",
       "      <td>4.17</td>\n",
       "      <td>9.04</td>\n",
       "      <td>147.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>CAN</td>\n",
       "      <td>10.98</td>\n",
       "      <td>22.62</td>\n",
       "      <td>49.91</td>\n",
       "      <td>1.97</td>\n",
       "      <td>4.00</td>\n",
       "      <td>8.54</td>\n",
       "      <td>148.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>CHI</td>\n",
       "      <td>11.65</td>\n",
       "      <td>23.84</td>\n",
       "      <td>53.68</td>\n",
       "      <td>2.00</td>\n",
       "      <td>4.22</td>\n",
       "      <td>9.26</td>\n",
       "      <td>152.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>CHN</td>\n",
       "      <td>10.79</td>\n",
       "      <td>22.01</td>\n",
       "      <td>49.81</td>\n",
       "      <td>1.93</td>\n",
       "      <td>3.84</td>\n",
       "      <td>8.10</td>\n",
       "      <td>139.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>COL</td>\n",
       "      <td>11.31</td>\n",
       "      <td>22.92</td>\n",
       "      <td>49.64</td>\n",
       "      <td>2.04</td>\n",
       "      <td>4.34</td>\n",
       "      <td>9.37</td>\n",
       "      <td>155.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>COK</td>\n",
       "      <td>12.52</td>\n",
       "      <td>25.91</td>\n",
       "      <td>61.65</td>\n",
       "      <td>2.28</td>\n",
       "      <td>4.82</td>\n",
       "      <td>11.10</td>\n",
       "      <td>212.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>CRC</td>\n",
       "      <td>11.72</td>\n",
       "      <td>23.92</td>\n",
       "      <td>52.57</td>\n",
       "      <td>2.10</td>\n",
       "      <td>4.52</td>\n",
       "      <td>9.84</td>\n",
       "      <td>164.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>CZE</td>\n",
       "      <td>11.09</td>\n",
       "      <td>21.97</td>\n",
       "      <td>47.99</td>\n",
       "      <td>1.89</td>\n",
       "      <td>4.03</td>\n",
       "      <td>8.87</td>\n",
       "      <td>145.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>DEN</td>\n",
       "      <td>11.42</td>\n",
       "      <td>23.36</td>\n",
       "      <td>52.92</td>\n",
       "      <td>2.02</td>\n",
       "      <td>4.12</td>\n",
       "      <td>8.71</td>\n",
       "      <td>149.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>DOM</td>\n",
       "      <td>11.63</td>\n",
       "      <td>23.91</td>\n",
       "      <td>53.02</td>\n",
       "      <td>2.09</td>\n",
       "      <td>4.54</td>\n",
       "      <td>9.89</td>\n",
       "      <td>166.46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>FIN</td>\n",
       "      <td>11.13</td>\n",
       "      <td>22.39</td>\n",
       "      <td>50.14</td>\n",
       "      <td>2.01</td>\n",
       "      <td>4.10</td>\n",
       "      <td>8.69</td>\n",
       "      <td>148.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>FRA</td>\n",
       "      <td>10.73</td>\n",
       "      <td>21.99</td>\n",
       "      <td>48.25</td>\n",
       "      <td>1.94</td>\n",
       "      <td>4.03</td>\n",
       "      <td>8.64</td>\n",
       "      <td>148.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>GER</td>\n",
       "      <td>10.81</td>\n",
       "      <td>21.71</td>\n",
       "      <td>47.60</td>\n",
       "      <td>1.92</td>\n",
       "      <td>3.96</td>\n",
       "      <td>8.51</td>\n",
       "      <td>141.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>GBR</td>\n",
       "      <td>11.10</td>\n",
       "      <td>22.10</td>\n",
       "      <td>49.43</td>\n",
       "      <td>1.94</td>\n",
       "      <td>3.97</td>\n",
       "      <td>8.37</td>\n",
       "      <td>135.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>GRE</td>\n",
       "      <td>11.57</td>\n",
       "      <td>22.94</td>\n",
       "      <td>52.50</td>\n",
       "      <td>2.05</td>\n",
       "      <td>4.25</td>\n",
       "      <td>9.19</td>\n",
       "      <td>150.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>GUA</td>\n",
       "      <td>11.92</td>\n",
       "      <td>24.50</td>\n",
       "      <td>55.64</td>\n",
       "      <td>2.15</td>\n",
       "      <td>4.48</td>\n",
       "      <td>9.71</td>\n",
       "      <td>171.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>HUN</td>\n",
       "      <td>11.41</td>\n",
       "      <td>23.06</td>\n",
       "      <td>51.50</td>\n",
       "      <td>1.99</td>\n",
       "      <td>4.02</td>\n",
       "      <td>8.55</td>\n",
       "      <td>148.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>INA</td>\n",
       "      <td>11.56</td>\n",
       "      <td>23.86</td>\n",
       "      <td>55.08</td>\n",
       "      <td>2.10</td>\n",
       "      <td>4.36</td>\n",
       "      <td>9.50</td>\n",
       "      <td>154.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>IND</td>\n",
       "      <td>11.38</td>\n",
       "      <td>22.82</td>\n",
       "      <td>51.05</td>\n",
       "      <td>2.00</td>\n",
       "      <td>4.10</td>\n",
       "      <td>9.11</td>\n",
       "      <td>158.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>IRL</td>\n",
       "      <td>11.43</td>\n",
       "      <td>23.02</td>\n",
       "      <td>51.07</td>\n",
       "      <td>2.01</td>\n",
       "      <td>3.98</td>\n",
       "      <td>8.36</td>\n",
       "      <td>142.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>ISR</td>\n",
       "      <td>11.45</td>\n",
       "      <td>23.15</td>\n",
       "      <td>52.06</td>\n",
       "      <td>2.07</td>\n",
       "      <td>4.24</td>\n",
       "      <td>9.33</td>\n",
       "      <td>156.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>ITA</td>\n",
       "      <td>11.14</td>\n",
       "      <td>22.60</td>\n",
       "      <td>51.31</td>\n",
       "      <td>1.96</td>\n",
       "      <td>3.98</td>\n",
       "      <td>8.59</td>\n",
       "      <td>143.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>JPN</td>\n",
       "      <td>11.36</td>\n",
       "      <td>23.33</td>\n",
       "      <td>51.93</td>\n",
       "      <td>2.01</td>\n",
       "      <td>4.16</td>\n",
       "      <td>8.74</td>\n",
       "      <td>139.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>KEN</td>\n",
       "      <td>11.62</td>\n",
       "      <td>23.37</td>\n",
       "      <td>51.56</td>\n",
       "      <td>1.97</td>\n",
       "      <td>3.96</td>\n",
       "      <td>8.39</td>\n",
       "      <td>138.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>KORN</td>\n",
       "      <td>11.49</td>\n",
       "      <td>23.80</td>\n",
       "      <td>53.67</td>\n",
       "      <td>2.09</td>\n",
       "      <td>4.24</td>\n",
       "      <td>9.01</td>\n",
       "      <td>146.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>KORS</td>\n",
       "      <td>11.80</td>\n",
       "      <td>25.10</td>\n",
       "      <td>56.23</td>\n",
       "      <td>1.97</td>\n",
       "      <td>4.25</td>\n",
       "      <td>8.96</td>\n",
       "      <td>145.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>LUX</td>\n",
       "      <td>11.76</td>\n",
       "      <td>23.96</td>\n",
       "      <td>56.07</td>\n",
       "      <td>2.07</td>\n",
       "      <td>4.35</td>\n",
       "      <td>9.21</td>\n",
       "      <td>149.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>MAS</td>\n",
       "      <td>11.50</td>\n",
       "      <td>23.37</td>\n",
       "      <td>52.56</td>\n",
       "      <td>2.12</td>\n",
       "      <td>4.39</td>\n",
       "      <td>9.31</td>\n",
       "      <td>169.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>MRI</td>\n",
       "      <td>11.72</td>\n",
       "      <td>23.83</td>\n",
       "      <td>54.62</td>\n",
       "      <td>2.06</td>\n",
       "      <td>4.33</td>\n",
       "      <td>9.24</td>\n",
       "      <td>167.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>MEX</td>\n",
       "      <td>11.09</td>\n",
       "      <td>23.13</td>\n",
       "      <td>48.89</td>\n",
       "      <td>2.02</td>\n",
       "      <td>4.19</td>\n",
       "      <td>8.89</td>\n",
       "      <td>144.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>MYA</td>\n",
       "      <td>11.66</td>\n",
       "      <td>23.69</td>\n",
       "      <td>52.96</td>\n",
       "      <td>2.03</td>\n",
       "      <td>4.20</td>\n",
       "      <td>9.08</td>\n",
       "      <td>158.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>NED</td>\n",
       "      <td>11.08</td>\n",
       "      <td>22.81</td>\n",
       "      <td>51.35</td>\n",
       "      <td>1.93</td>\n",
       "      <td>4.06</td>\n",
       "      <td>8.57</td>\n",
       "      <td>143.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>NZL</td>\n",
       "      <td>11.32</td>\n",
       "      <td>23.13</td>\n",
       "      <td>51.60</td>\n",
       "      <td>1.97</td>\n",
       "      <td>4.10</td>\n",
       "      <td>8.76</td>\n",
       "      <td>146.46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>NOR</td>\n",
       "      <td>11.41</td>\n",
       "      <td>23.31</td>\n",
       "      <td>52.45</td>\n",
       "      <td>2.03</td>\n",
       "      <td>4.01</td>\n",
       "      <td>8.53</td>\n",
       "      <td>141.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>PNG</td>\n",
       "      <td>11.96</td>\n",
       "      <td>24.68</td>\n",
       "      <td>55.18</td>\n",
       "      <td>2.24</td>\n",
       "      <td>4.12</td>\n",
       "      <td>10.21</td>\n",
       "      <td>221.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>PHI</td>\n",
       "      <td>11.28</td>\n",
       "      <td>23.35</td>\n",
       "      <td>54.75</td>\n",
       "      <td>2.12</td>\n",
       "      <td>4.41</td>\n",
       "      <td>9.81</td>\n",
       "      <td>165.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>POL</td>\n",
       "      <td>10.93</td>\n",
       "      <td>22.13</td>\n",
       "      <td>49.28</td>\n",
       "      <td>1.95</td>\n",
       "      <td>3.99</td>\n",
       "      <td>8.53</td>\n",
       "      <td>144.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>POR</td>\n",
       "      <td>11.30</td>\n",
       "      <td>22.88</td>\n",
       "      <td>51.92</td>\n",
       "      <td>1.98</td>\n",
       "      <td>3.96</td>\n",
       "      <td>8.50</td>\n",
       "      <td>143.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>ROM</td>\n",
       "      <td>11.30</td>\n",
       "      <td>22.35</td>\n",
       "      <td>49.88</td>\n",
       "      <td>1.92</td>\n",
       "      <td>3.90</td>\n",
       "      <td>8.36</td>\n",
       "      <td>142.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>RUS</td>\n",
       "      <td>10.77</td>\n",
       "      <td>21.87</td>\n",
       "      <td>49.11</td>\n",
       "      <td>1.91</td>\n",
       "      <td>3.87</td>\n",
       "      <td>8.38</td>\n",
       "      <td>141.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>SAM</td>\n",
       "      <td>12.38</td>\n",
       "      <td>25.45</td>\n",
       "      <td>56.32</td>\n",
       "      <td>2.29</td>\n",
       "      <td>5.92</td>\n",
       "      <td>13.12</td>\n",
       "      <td>191.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>SIN</td>\n",
       "      <td>12.13</td>\n",
       "      <td>24.54</td>\n",
       "      <td>55.08</td>\n",
       "      <td>2.12</td>\n",
       "      <td>4.52</td>\n",
       "      <td>9.94</td>\n",
       "      <td>154.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>ESP</td>\n",
       "      <td>11.06</td>\n",
       "      <td>22.38</td>\n",
       "      <td>49.67</td>\n",
       "      <td>1.96</td>\n",
       "      <td>4.01</td>\n",
       "      <td>8.48</td>\n",
       "      <td>146.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>SWE</td>\n",
       "      <td>11.16</td>\n",
       "      <td>22.82</td>\n",
       "      <td>51.69</td>\n",
       "      <td>1.99</td>\n",
       "      <td>4.09</td>\n",
       "      <td>8.81</td>\n",
       "      <td>150.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>SUI</td>\n",
       "      <td>11.34</td>\n",
       "      <td>22.88</td>\n",
       "      <td>51.32</td>\n",
       "      <td>1.98</td>\n",
       "      <td>3.97</td>\n",
       "      <td>8.60</td>\n",
       "      <td>145.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>TPE</td>\n",
       "      <td>11.22</td>\n",
       "      <td>22.56</td>\n",
       "      <td>52.74</td>\n",
       "      <td>2.08</td>\n",
       "      <td>4.38</td>\n",
       "      <td>9.63</td>\n",
       "      <td>159.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>THA</td>\n",
       "      <td>11.33</td>\n",
       "      <td>23.30</td>\n",
       "      <td>52.60</td>\n",
       "      <td>2.06</td>\n",
       "      <td>4.38</td>\n",
       "      <td>10.07</td>\n",
       "      <td>162.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>TUR</td>\n",
       "      <td>11.25</td>\n",
       "      <td>22.71</td>\n",
       "      <td>53.15</td>\n",
       "      <td>2.01</td>\n",
       "      <td>3.92</td>\n",
       "      <td>8.53</td>\n",
       "      <td>151.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>USA</td>\n",
       "      <td>10.49</td>\n",
       "      <td>21.34</td>\n",
       "      <td>48.70</td>\n",
       "      <td>1.94</td>\n",
       "      <td>3.95</td>\n",
       "      <td>8.43</td>\n",
       "      <td>139.60</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Country   100m   200m   400m  800m  1500m  3000m  Marathon\n",
       "0      ARG  10.83  22.67  50.56  2.00   4.09   8.96    153.40\n",
       "1      AUS  11.12  22.23  48.63  1.98   4.02   8.63    143.51\n",
       "2      AUT  11.15  22.70  50.62  1.94   4.05   8.78    154.35\n",
       "3      BEL  11.14  22.48  51.45  1.97   4.08   8.82    143.05\n",
       "4      BER  11.46  23.05  53.30  2.07   4.29   9.81    174.18\n",
       "5      BRA  11.17  22.60  50.62  1.97   4.17   9.04    147.41\n",
       "6      CAN  10.98  22.62  49.91  1.97   4.00   8.54    148.36\n",
       "7      CHI  11.65  23.84  53.68  2.00   4.22   9.26    152.23\n",
       "8      CHN  10.79  22.01  49.81  1.93   3.84   8.10    139.39\n",
       "9      COL  11.31  22.92  49.64  2.04   4.34   9.37    155.19\n",
       "10     COK  12.52  25.91  61.65  2.28   4.82  11.10    212.33\n",
       "11     CRC  11.72  23.92  52.57  2.10   4.52   9.84    164.33\n",
       "12     CZE  11.09  21.97  47.99  1.89   4.03   8.87    145.19\n",
       "13     DEN  11.42  23.36  52.92  2.02   4.12   8.71    149.34\n",
       "14     DOM  11.63  23.91  53.02  2.09   4.54   9.89    166.46\n",
       "15     FIN  11.13  22.39  50.14  2.01   4.10   8.69    148.00\n",
       "16     FRA  10.73  21.99  48.25  1.94   4.03   8.64    148.27\n",
       "17     GER  10.81  21.71  47.60  1.92   3.96   8.51    141.45\n",
       "18     GBR  11.10  22.10  49.43  1.94   3.97   8.37    135.25\n",
       "19     GRE  11.57  22.94  52.50  2.05   4.25   9.19    150.32\n",
       "20     GUA  11.92  24.50  55.64  2.15   4.48   9.71    171.33\n",
       "21     HUN  11.41  23.06  51.50  1.99   4.02   8.55    148.50\n",
       "22     INA  11.56  23.86  55.08  2.10   4.36   9.50    154.29\n",
       "23     IND  11.38  22.82  51.05  2.00   4.10   9.11    158.10\n",
       "24     IRL  11.43  23.02  51.07  2.01   3.98   8.36    142.23\n",
       "25     ISR  11.45  23.15  52.06  2.07   4.24   9.33    156.36\n",
       "26     ITA  11.14  22.60  51.31  1.96   3.98   8.59    143.47\n",
       "27     JPN  11.36  23.33  51.93  2.01   4.16   8.74    139.41\n",
       "28     KEN  11.62  23.37  51.56  1.97   3.96   8.39    138.47\n",
       "29    KORN  11.49  23.80  53.67  2.09   4.24   9.01    146.12\n",
       "30    KORS  11.80  25.10  56.23  1.97   4.25   8.96    145.31\n",
       "31     LUX  11.76  23.96  56.07  2.07   4.35   9.21    149.23\n",
       "32     MAS  11.50  23.37  52.56  2.12   4.39   9.31    169.28\n",
       "33     MRI  11.72  23.83  54.62  2.06   4.33   9.24    167.09\n",
       "34     MEX  11.09  23.13  48.89  2.02   4.19   8.89    144.06\n",
       "35     MYA  11.66  23.69  52.96  2.03   4.20   9.08    158.42\n",
       "36     NED  11.08  22.81  51.35  1.93   4.06   8.57    143.43\n",
       "37     NZL  11.32  23.13  51.60  1.97   4.10   8.76    146.46\n",
       "38     NOR  11.41  23.31  52.45  2.03   4.01   8.53    141.06\n",
       "39     PNG  11.96  24.68  55.18  2.24   4.12  10.21    221.14\n",
       "40     PHI  11.28  23.35  54.75  2.12   4.41   9.81    165.48\n",
       "41     POL  10.93  22.13  49.28  1.95   3.99   8.53    144.18\n",
       "42     POR  11.30  22.88  51.92  1.98   3.96   8.50    143.29\n",
       "43     ROM  11.30  22.35  49.88  1.92   3.90   8.36    142.50\n",
       "44     RUS  10.77  21.87  49.11  1.91   3.87   8.38    141.31\n",
       "45     SAM  12.38  25.45  56.32  2.29   5.92  13.12    191.58\n",
       "46     SIN  12.13  24.54  55.08  2.12   4.52   9.94    154.41\n",
       "47     ESP  11.06  22.38  49.67  1.96   4.01   8.48    146.51\n",
       "48     SWE  11.16  22.82  51.69  1.99   4.09   8.81    150.39\n",
       "49     SUI  11.34  22.88  51.32  1.98   3.97   8.60    145.51\n",
       "50     TPE  11.22  22.56  52.74  2.08   4.38   9.63    159.53\n",
       "51     THA  11.33  23.30  52.60  2.06   4.38  10.07    162.39\n",
       "52     TUR  11.25  22.71  53.15  2.01   3.92   8.53    151.43\n",
       "53     USA  10.49  21.34  48.70  1.94   3.95   8.43    139.60"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lendo os dados\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "np.set_printoptions(precision=3)\n",
    "\n",
    "df = pd.read_csv('p1.txt',sep='\\t',header=None,names=[\"Country\",\"100m\",\"200m\",\"400m\",\"800m\",\"1500m\",\"3000m\",\"Marathon\"])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "1c11c44f0ba68e68f3550628789949ba",
     "grade": false,
     "grade_id": "cell-d4bf8b1d4c8964aa",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Administrador.000\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "# extraindo a matriz de dados e os nomes dos países\n",
    "X = df.drop('Country',axis=1).as_matrix()\n",
    "countries = list(df['Country'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "f44df4f3528ac0729db5050d422fc5a1",
     "grade": false,
     "grade_id": "cell-73b681d48cfb2caa",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "## Questão resolvida\n",
    "\n",
    "Para cada variável (coluna), calcule a média usando ```np.mean``` e a variância usando ```np.var```. Use a função ```np.round``` para arredondar o resultado para 3 casas decimais."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "6b7e8ef6706a36c7357f10750a053654",
     "grade": false,
     "grade_id": "cell-565714b9f7bdde0a",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 11.358  23.119  51.987   2.022   4.189   9.081 153.59 ]\n",
      "[1.553e-01 8.631e-01 6.761e+00 7.547e-03 9.871e-02 6.648e-01 2.710e+02]\n"
     ]
    }
   ],
   "source": [
    "# calculando a média mu e a variância sigma2 (o ddof=1 é usado para que o denominador seja m-1)\n",
    "\n",
    "mu = np.mean(X,axis=0)\n",
    "sigma2 = np.var(X,axis=0,ddof=1)\n",
    "\n",
    "print(mu)\n",
    "print(sigma2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "df6ae458ac994f3e662e7b01ddd491e9",
     "grade": false,
     "grade_id": "cell-fc7e4588f578ed6c",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "## Questão resolvida\n",
    "\n",
    "Transforme a matriz ```X``` em ```X_centered``` subtraindo a média de cada variável."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "757e98d8e9b983b70bd7db5c1090d510",
     "grade": false,
     "grade_id": "cell-5118ef8504543054",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ -0.528,  -0.449,  -1.427,  -0.022,  -0.099,  -0.121,  -0.19 ],\n",
       "       [ -0.238,  -0.889,  -3.357,  -0.042,  -0.169,  -0.451, -10.08 ],\n",
       "       [ -0.208,  -0.419,  -1.367,  -0.082,  -0.139,  -0.301,   0.76 ],\n",
       "       [ -0.218,  -0.639,  -0.537,  -0.052,  -0.109,  -0.261, -10.54 ],\n",
       "       [  0.102,  -0.069,   1.313,   0.048,   0.101,   0.729,  20.59 ]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# neste caso, a subtração entre matriz e vetor faz com que o vetor seja subtraído de cada linha da matriz\n",
    "\n",
    "m,n = X.shape\n",
    "#Mu = mu.repeat(m).reshape((n,m)).T\n",
    "X_centered = X-mu\n",
    "X_centered[:5,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "517bb04daa1c334e75bfb98f60bcf244",
     "grade": false,
     "grade_id": "cell-8d38882f5280a54c",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "## Questão resolvida\n",
    "\n",
    "Agora normalize a matriz ```X_centered``` dividindo cada entrada pelo seu desvio padrão. Salve o resultado em ```X_normalized```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "55faa634ddc4cc461d82b3d005f494e7",
     "grade": false,
     "grade_id": "cell-f9c51eca92ab6463",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.339, -0.483, -0.549, -0.258, -0.317, -0.148, -0.012],\n",
       "       [-0.603, -0.956, -1.291, -0.488, -0.539, -0.553, -0.612],\n",
       "       [-0.527, -0.45 , -0.526, -0.949, -0.444, -0.369,  0.046],\n",
       "       [-0.553, -0.687, -0.206, -0.603, -0.348, -0.32 , -0.64 ],\n",
       "       [ 0.259, -0.074,  0.505,  0.548,  0.32 ,  0.894,  1.251]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# neste caso, a divisão entre matriz e vetor faz com que cada linha da matriz seja dividida elemento-a-elemento pelo vetor\n",
    "\n",
    "sigma = np.sqrt(sigma2)\n",
    "#Sigma = sigma.repeat(m).reshape((n,m)).T\n",
    "X_normalized = X_centered/np.sqrt(sigma2)\n",
    "X_normalized[:5,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "e410ef6fe549e1b94b534b06c3259584",
     "grade": false,
     "grade_id": "cell-cc2e8dfe5ab74a39",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "## Questão 1\n",
    "\n",
    "Defina uma matriz que receba como entrada uma matriz $\\mathbf{A}_{m \\times n}$ de $m$ observações por $n$ variáveis que já foi centralizada e normalizada e retorne a matriz de covariância das variáveis. A função **não pode** utilizar a função ```numpy.cov```, mas sim utilizar a fórmula vista em sala ($m-1$ como denominador)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "fc63b64de97f00071511a2f62f66760b",
     "grade": false,
     "grade_id": "cell-91a09055d06bcd96",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def calculaCov(A):\n",
    "    # YOUR CODE HERE\n",
    "    m = A.shape[0]\n",
    "    cov = A.T@A\n",
    "    cov = cov/(m-1)\n",
    "    #raise NotImplementedError()\n",
    "    return cov"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "549533eee38479713e9c87fadef142e3",
     "grade": false,
     "grade_id": "cell-3ec6b54ab4e534eb",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "Certifique-se de que o resultado para a matriz ```X_normalized``` é igual aquele encontrado no arquivo ```cov.npz```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "0d854193542d318e9ad994f3fbc8c0ad",
     "grade": true,
     "grade_id": "cell-b600d280016f7f07",
     "locked": true,
     "points": 1,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "cov = calculaCov(X_normalized)\n",
    "with open('cov.npz','rb') as f: \n",
    "    saida = np.load(f)\n",
    "\n",
    "assert np.allclose(cov,saida)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "110a9b8c6de3d2b7b063c2d191715105",
     "grade": false,
     "grade_id": "cell-b93e0acb3a754ef9",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "## Questão 2\n",
    "\n",
    "Vamos construir a matriz $P = E^\\top$ contendo as duas componentes principais. \n",
    "Para isso, você deve obter os dois autovetores dos maiores autovalores em módulo da matriz ```cov``` usando ```np.linalg.eig```.\n",
    "\n",
    "O resultado obtido usando PCA é mostrado a seguir. É possível que alguns autovetores/componentes tenham sinais opostos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "a005215748a9c1799cbb6bec7ca72907",
     "grade": false,
     "grade_id": "cell-24baf5a8f862dffc",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components=2)\n",
    "X_r = pca.fit(X_normalized).transform(X_normalized)\n",
    "pca.components_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "e523542589ee498200fec6db87ba7d0c",
     "grade": false,
     "grade_id": "cell-7de661c72abbb8cf",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def calculaMatrizP(cov, n_componentes):\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    return P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "5cd9587e052e54ca9af054d4691e84d6",
     "grade": true,
     "grade_id": "cell-2343740bbde73d49",
     "locked": true,
     "points": 1,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "P = calculaMatrizP(cov, 2)\n",
    "print(P)\n",
    "\n",
    "assert (\n",
    "    np.allclose(P[0],pca.components_[0]) or np.allclose(P[0],-pca.components_[0])\n",
    ") and (\n",
    "    np.allclose(P[1],pca.components_[1]) or np.allclose(P[1],-pca.components_[1])\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "f878f06f86627153bfd823ce99a336e2",
     "grade": false,
     "grade_id": "cell-3860d77cc37b59c4",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "## Questão 3\n",
    "\n",
    "Calcule a porcentagem da variância total explicada pelo primeiro e segundo componentes principais. Para isto é preciso normalizar os autovalores obtidos no passo anterior pela soma de todos os $n$ autovalores.\n",
    "\n",
    "O resultado obtido usando PCA é mostrado a seguir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "010d6751f635a6c039274a52bb286f99",
     "grade": false,
     "grade_id": "cell-9c930b5992b0540e",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "pca.explained_variance_ratio_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "aeed1ca487be2449f498c412b5d74c3b",
     "grade": false,
     "grade_id": "cell-5e1d744410fc4fad",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def calculaVarianciaExplicada(cov, n_componentes):\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    return var_explicada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "5d9cdf5c1e324ff7304ff06fd87daf52",
     "grade": true,
     "grade_id": "cell-41b7faf4aa170084",
     "locked": true,
     "points": 1,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "var_explicada = calculaVarianciaExplicada(cov, 2)\n",
    "assert np.allclose(var_explicada,pca.explained_variance_ratio_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "9b9e66f5d5098fed8895bece038b75c9",
     "grade": false,
     "grade_id": "cell-0a35dc71bc2dfeb5",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "## Questão 4\n",
    "\n",
    "As linhas de ```P``` formam uma base ortogonal. A projeção das linhas de ```X_normalized``` nas linhas de ```P``` geram uma representação para cada país no plano (PC1, PC2). Construa um diagrama de dispersão 2D das 54 observações no plano (PC1, PC2).\n",
    "\n",
    "O resultado obtido usando PCA é mostrado a seguir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "2061353c515b22d59d25fdea3ab57bd1",
     "grade": false,
     "grade_id": "cell-1ea29ddcaa4ae2c2",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "X_r = pca.fit(X_normalized).transform(X_normalized)\n",
    "plt.scatter(X_r[:,0],X_r[:,1])\n",
    "for i in range(X_r.shape[0]):\n",
    "    plt.annotate(countries[i],xy=(X_r[i,0],X_r[i,1]),xytext=(0,5),\n",
    "                 textcoords='offset points', ha='center', va='bottom')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "aabf2c5e0e227c5596efdd3a7e16dc99",
     "grade": true,
     "grade_id": "cell-904b66840679bdeb",
     "locked": false,
     "points": 1,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def plotaDiagramaDispersao(P, X_normalized):\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "e584d97b27d4155b9534891015180cc3",
     "grade": false,
     "grade_id": "cell-2e015b71e4a84b05",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "## Questão 5\n",
    "\n",
    "Considerando o gráfico anterior, que país poderia ser considerado um outlier? O nome do país pode ser consultado [aqui](https://countrycode.org/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "8ffbc3a3d018f6981b40e8253f66ccbf",
     "grade": true,
     "grade_id": "cell-3012fddc53a09381",
     "locked": false,
     "points": 1,
     "schema_version": 1,
     "solution": true
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
